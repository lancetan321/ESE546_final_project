{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/facebookresearch/detr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#CV\n",
    "import cv2\n",
    "\n",
    "################# DETR FUCNTIONS FOR LOSS########################\n",
    "import sys\n",
    "sys.path.append('./detr/')\n",
    "\n",
    "from detr.models.matcher import HungarianMatcher\n",
    "from detr.models.detr import SetCriterion\n",
    "#################################################################\n",
    "\n",
    "#Albumenatations\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "#Glob\n",
    "from glob import glob\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(A.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.backends.cudnn.enabled = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "seed = 42\n",
    "num_classes = 11\n",
    "num_queries = 65 #changed from 100\n",
    "null_class_coef = 0.5\n",
    "BATCH_SIZE = 8\n",
    "LR = 2e-5\n",
    "EPOCHS = 2\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>videoName</th>\n",
       "      <th>frameIndex</th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>attributes.crowd</th>\n",
       "      <th>attributes.occluded</th>\n",
       "      <th>attributes.truncated</th>\n",
       "      <th>box2d.x1</th>\n",
       "      <th>box2d.x2</th>\n",
       "      <th>box2d.y1</th>\n",
       "      <th>box2d.y2</th>\n",
       "      <th>haveVideo</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01c71072-718028b8-0000001.jpg</td>\n",
       "      <td>01c71072-718028b8</td>\n",
       "      <td>0</td>\n",
       "      <td>89537.0</td>\n",
       "      <td>car</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>825.173210</td>\n",
       "      <td>1003.094688</td>\n",
       "      <td>355.011547</td>\n",
       "      <td>418.198614</td>\n",
       "      <td>True</td>\n",
       "      <td>825.173210</td>\n",
       "      <td>355.011547</td>\n",
       "      <td>177.921478</td>\n",
       "      <td>63.187067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01c71072-718028b8-0000001.jpg</td>\n",
       "      <td>01c71072-718028b8</td>\n",
       "      <td>0</td>\n",
       "      <td>89538.0</td>\n",
       "      <td>car</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>484.295612</td>\n",
       "      <td>700.461894</td>\n",
       "      <td>346.697460</td>\n",
       "      <td>424.849885</td>\n",
       "      <td>True</td>\n",
       "      <td>484.295612</td>\n",
       "      <td>346.697460</td>\n",
       "      <td>216.166282</td>\n",
       "      <td>78.152425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01c71072-718028b8-0000001.jpg</td>\n",
       "      <td>01c71072-718028b8</td>\n",
       "      <td>0</td>\n",
       "      <td>89539.0</td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>645.588915</td>\n",
       "      <td>663.879908</td>\n",
       "      <td>338.383372</td>\n",
       "      <td>358.337182</td>\n",
       "      <td>True</td>\n",
       "      <td>645.588915</td>\n",
       "      <td>338.383372</td>\n",
       "      <td>18.290993</td>\n",
       "      <td>19.953811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01c71072-718028b8-0000001.jpg</td>\n",
       "      <td>01c71072-718028b8</td>\n",
       "      <td>0</td>\n",
       "      <td>89540.0</td>\n",
       "      <td>car</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>120.969977</td>\n",
       "      <td>192.471132</td>\n",
       "      <td>359.168591</td>\n",
       "      <td>409.053118</td>\n",
       "      <td>True</td>\n",
       "      <td>120.969977</td>\n",
       "      <td>359.168591</td>\n",
       "      <td>71.501155</td>\n",
       "      <td>49.884527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01c71072-718028b8-0000001.jpg</td>\n",
       "      <td>01c71072-718028b8</td>\n",
       "      <td>0</td>\n",
       "      <td>89541.0</td>\n",
       "      <td>car</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>251.501155</td>\n",
       "      <td>315.519630</td>\n",
       "      <td>354.180139</td>\n",
       "      <td>400.739030</td>\n",
       "      <td>True</td>\n",
       "      <td>251.501155</td>\n",
       "      <td>354.180139</td>\n",
       "      <td>64.018476</td>\n",
       "      <td>46.558891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name          videoName  frameIndex       id  \\\n",
       "0  01c71072-718028b8-0000001.jpg  01c71072-718028b8           0  89537.0   \n",
       "1  01c71072-718028b8-0000001.jpg  01c71072-718028b8           0  89538.0   \n",
       "2  01c71072-718028b8-0000001.jpg  01c71072-718028b8           0  89539.0   \n",
       "3  01c71072-718028b8-0000001.jpg  01c71072-718028b8           0  89540.0   \n",
       "4  01c71072-718028b8-0000001.jpg  01c71072-718028b8           0  89541.0   \n",
       "\n",
       "     category attributes.crowd attributes.occluded attributes.truncated  \\\n",
       "0         car            False                True                False   \n",
       "1         car            False                True                False   \n",
       "2  pedestrian            False                True                False   \n",
       "3         car            False               False                False   \n",
       "4         car            False               False                False   \n",
       "\n",
       "     box2d.x1     box2d.x2    box2d.y1    box2d.y2  haveVideo           x  \\\n",
       "0  825.173210  1003.094688  355.011547  418.198614       True  825.173210   \n",
       "1  484.295612   700.461894  346.697460  424.849885       True  484.295612   \n",
       "2  645.588915   663.879908  338.383372  358.337182       True  645.588915   \n",
       "3  120.969977   192.471132  359.168591  409.053118       True  120.969977   \n",
       "4  251.501155   315.519630  354.180139  400.739030       True  251.501155   \n",
       "\n",
       "            y           w          h  \n",
       "0  355.011547  177.921478  63.187067  \n",
       "1  346.697460  216.166282  78.152425  \n",
       "2  338.383372   18.290993  19.953811  \n",
       "3  359.168591   71.501155  49.884527  \n",
       "4  354.180139   64.018476  46.558891  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mot_labels.csv')\n",
    "df['x'] = df['box2d.x1']\n",
    "df['y'] = df['box2d.y1']\n",
    "df['w'] = df['box2d.x2'] - df['box2d.x1']\n",
    "df['h'] = df['box2d.y2'] - df['box2d.y1']\n",
    "df = df[df['haveVideo'] == True].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpegs = os.listdir('frames_v2')\n",
    "df_cleaned = df[df['name'].isin(jpegs)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189580"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jpegs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split (if not done yet, otherwise import text file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# videos = list(df_cleaned['videoName'].drop_duplicates())\n",
    "# video_subset = random.sample(videos, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy_videos = [\n",
    "#     '003e23ee-67d25f19',\n",
    "#     '012a9c41-cef5b320',\n",
    "#     '00091078-59817bb0',\n",
    "#     '003baca5-aab2e274',\n",
    "#     '011aeca1-fe5af665'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subset = df_cleaned[df_cleaned['videoName'].isin(video_subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_counts = df_subset.groupby(['videoName', 'category']).size().unstack(fill_value=0)\n",
    "# class_counts.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract features and labels\n",
    "# X = class_counts['videoName'].values.reshape(-1, 1)  # Features are just the video IDs\n",
    "# y = class_counts.iloc[:, 1:].values  # Labels are the counts of each object class\n",
    "\n",
    "# # Initialize the multi-label stratified shuffle splitter\n",
    "# # Set test_size to the desired proportion, e.g., 0.2 for 20%\n",
    "# msss = MultilabelStratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Perform the split\n",
    "# train_fold_idx_list = []\n",
    "# test_fold_idx_list = []\n",
    "# for train_index, test_index in msss.split(X, y):\n",
    "#     # Split the dataframe into train and test sets based on the indices\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Class Distribution:\n",
      "bicycle           10766335\n",
      "bus               21932579\n",
      "car              876702660\n",
      "motorcycle         3870359\n",
      "other person        845605\n",
      "other vehicle      9799440\n",
      "pedestrian       229244850\n",
      "rider              5201947\n",
      "trailer             686329\n",
      "train               452005\n",
      "truck             64473339\n",
      "dtype: int64\n",
      "------------------------------\n",
      "Test Class Distribution:\n",
      "bicycle            4196046\n",
      "bus                8140554\n",
      "car              197036639\n",
      "motorcycle         1201821\n",
      "other person        676948\n",
      "other vehicle      2451641\n",
      "pedestrian        45896359\n",
      "rider              3697872\n",
      "trailer             175814\n",
      "train                 7064\n",
      "truck             10786866\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# X_train_list = [videoName[0] for videoName in X_train]\n",
    "# X_test_list = [videoName[0] for videoName in X_test]\n",
    "# counts_train_df = class_counts[class_counts['videoName'].isin(X_train_list)]\n",
    "# counts_test_df = class_counts[class_counts['videoName'].isin(X_test_list)]\n",
    "# train_counts_df = pd.merge(df, counts_train_df, on='videoName')\n",
    "# test_counts_df = pd.merge(df, counts_test_df, on='videoName')\n",
    "\n",
    "# labels = df['category'].dropna().unique()\n",
    "# train_class_distribution = train_counts_df[labels].sum().sort_index()\n",
    "# test_class_distribution = test_counts_df[labels].sum().sort_index()\n",
    "\n",
    "# print('Train Class Distribution:')\n",
    "# print(train_class_distribution)\n",
    "# print('-' * 30)\n",
    "# print('Test Class Distribution:')\n",
    "# print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Train Distribution  Test Distribution\n",
      "bicycle                  0.008317           0.012142\n",
      "bus                      0.017638           0.025338\n",
      "car                      0.754619           0.760541\n",
      "motorcycle               0.003298           0.003694\n",
      "other person             0.000641           0.001552\n",
      "other vehicle            0.007602           0.006763\n",
      "pedestrian               0.152264           0.132969\n",
      "rider                    0.004112           0.009832\n",
      "trailer                  0.000557           0.000303\n",
      "train                    0.000390           0.000036\n",
      "truck                    0.050563           0.046830\n"
     ]
    }
   ],
   "source": [
    "# train_class_distribution = train_counts_df['category'].value_counts(normalize=True)\n",
    "# test_class_distribution = test_counts_df['category'].value_counts(normalize=True)\n",
    "\n",
    "# # Create a DataFrame to compare the distributions\n",
    "# comparison_df = pd.DataFrame({\n",
    "#     'Train Distribution': train_class_distribution,\n",
    "#     'Test Distribution': test_class_distribution\n",
    "# })\n",
    "\n",
    "# print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 60)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(X_train_list), len(X_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# train_series = pd.Series(X_train_list)\n",
    "# test_series = pd.Series(X_test_list)\n",
    "\n",
    "# train_series.to_csv('train_videos_small.csv')\n",
    "# test_series.to_csv('test_videos_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 60)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df = pd.read_csv('train_videos_small.csv', header = None, index_col = 0)\n",
    "X_test_df = pd.read_csv('test_videos_small.csv', header = None, index_col = 0)\n",
    "\n",
    "X_train_list = list(X_train_df[1])\n",
    "X_test_list = list(X_test_df[1])\n",
    "\n",
    "len(X_train_list), len(X_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_cleaned[df_cleaned['videoName'].isin(X_train_list)].copy()\n",
    "test_df = df_cleaned[df_cleaned['videoName'].isin(X_test_list)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>videoName</th>\n",
       "      <th>frameIndex</th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>attributes.crowd</th>\n",
       "      <th>attributes.occluded</th>\n",
       "      <th>attributes.truncated</th>\n",
       "      <th>box2d.x1</th>\n",
       "      <th>box2d.x2</th>\n",
       "      <th>box2d.y1</th>\n",
       "      <th>box2d.y2</th>\n",
       "      <th>haveVideo</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>0252f2b5-1f4c92f2-0000002.jpg</td>\n",
       "      <td>0252f2b5-1f4c92f2</td>\n",
       "      <td>1</td>\n",
       "      <td>4563.0</td>\n",
       "      <td>car</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>305.298045</td>\n",
       "      <td>539.596577</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>539.596577</td>\n",
       "      <td>305.298045</td>\n",
       "      <td>180.403423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>0252f2b5-1f4c92f2-0000002.jpg</td>\n",
       "      <td>0252f2b5-1f4c92f2</td>\n",
       "      <td>1</td>\n",
       "      <td>4564.0</td>\n",
       "      <td>car</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>262.698315</td>\n",
       "      <td>374.038518</td>\n",
       "      <td>625.764213</td>\n",
       "      <td>718.709078</td>\n",
       "      <td>True</td>\n",
       "      <td>262.698315</td>\n",
       "      <td>625.764213</td>\n",
       "      <td>111.340203</td>\n",
       "      <td>92.944865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>0252f2b5-1f4c92f2-0000002.jpg</td>\n",
       "      <td>0252f2b5-1f4c92f2</td>\n",
       "      <td>1</td>\n",
       "      <td>4565.0</td>\n",
       "      <td>car</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>300.457166</td>\n",
       "      <td>433.097234</td>\n",
       "      <td>600.591645</td>\n",
       "      <td>718.709078</td>\n",
       "      <td>True</td>\n",
       "      <td>300.457166</td>\n",
       "      <td>600.591645</td>\n",
       "      <td>132.640068</td>\n",
       "      <td>118.117433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>0252f2b5-1f4c92f2-0000002.jpg</td>\n",
       "      <td>0252f2b5-1f4c92f2</td>\n",
       "      <td>1</td>\n",
       "      <td>4566.0</td>\n",
       "      <td>car</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>417.606423</td>\n",
       "      <td>466.015207</td>\n",
       "      <td>623.827862</td>\n",
       "      <td>697.409213</td>\n",
       "      <td>True</td>\n",
       "      <td>417.606423</td>\n",
       "      <td>623.827862</td>\n",
       "      <td>48.408784</td>\n",
       "      <td>73.581352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>0252f2b5-1f4c92f2-0000002.jpg</td>\n",
       "      <td>0252f2b5-1f4c92f2</td>\n",
       "      <td>1</td>\n",
       "      <td>4567.0</td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>478.601491</td>\n",
       "      <td>491.187775</td>\n",
       "      <td>621.891510</td>\n",
       "      <td>663.523064</td>\n",
       "      <td>True</td>\n",
       "      <td>478.601491</td>\n",
       "      <td>621.891510</td>\n",
       "      <td>12.586284</td>\n",
       "      <td>41.631554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name          videoName  frameIndex      id  \\\n",
       "3357  0252f2b5-1f4c92f2-0000002.jpg  0252f2b5-1f4c92f2           1  4563.0   \n",
       "3358  0252f2b5-1f4c92f2-0000002.jpg  0252f2b5-1f4c92f2           1  4564.0   \n",
       "3359  0252f2b5-1f4c92f2-0000002.jpg  0252f2b5-1f4c92f2           1  4565.0   \n",
       "3360  0252f2b5-1f4c92f2-0000002.jpg  0252f2b5-1f4c92f2           1  4566.0   \n",
       "3361  0252f2b5-1f4c92f2-0000002.jpg  0252f2b5-1f4c92f2           1  4567.0   \n",
       "\n",
       "        category attributes.crowd attributes.occluded attributes.truncated  \\\n",
       "3357         car            False               False                 True   \n",
       "3358         car            False                True                 True   \n",
       "3359         car            False                True                False   \n",
       "3360         car            False                True                False   \n",
       "3361  pedestrian            False                True                False   \n",
       "\n",
       "        box2d.x1    box2d.x2    box2d.y1    box2d.y2  haveVideo           x  \\\n",
       "3357    0.000000  305.298045  539.596577  720.000000       True    0.000000   \n",
       "3358  262.698315  374.038518  625.764213  718.709078       True  262.698315   \n",
       "3359  300.457166  433.097234  600.591645  718.709078       True  300.457166   \n",
       "3360  417.606423  466.015207  623.827862  697.409213       True  417.606423   \n",
       "3361  478.601491  491.187775  621.891510  663.523064       True  478.601491   \n",
       "\n",
       "               y           w           h  \n",
       "3357  539.596577  305.298045  180.403423  \n",
       "3358  625.764213  111.340203   92.944865  \n",
       "3359  600.591645  132.640068  118.117433  \n",
       "3360  623.827862   48.408784   73.581352  \n",
       "3361  621.891510   12.586284   41.631554  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_videos = [\n",
    "    '003e23ee-67d25f19',\n",
    "    '012a9c41-cef5b320',\n",
    "    '00091078-59817bb0',\n",
    "    '003baca5-aab2e274',\n",
    "    '011aeca1-fe5af665'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose([A.OneOf([A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, val_shift_limit=0.2, p=0.9),\n",
    "\n",
    "                      A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.9)],p=0.9),\n",
    "\n",
    "                      A.ToGray(p=0.01),\n",
    "\n",
    "                      A.VerticalFlip(p=0.5),\n",
    "                      \n",
    "                      #A.augmentations.geometric.resize.LongestMaxSize(max_size=64, p=1),\n",
    "\n",
    "                      #A.Resize(height=512, width=512, p=0), #changed to p=0 from p=1 to get rid of it\n",
    "\n",
    "                      #A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n",
    "\n",
    "                      ToTensorV2(p=1.0)],\n",
    "\n",
    "                      p=1.0,\n",
    "\n",
    "                      bbox_params=A.BboxParams(format='coco',min_area=0, min_visibility=0,label_fields=['labels'])\n",
    "                      )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose([A.Resize(height=512, width=512, p=0),\n",
    "                      ToTensorV2(p=1.0)],\n",
    "                      p=1.0,\n",
    "                      bbox_params=A.BboxParams(format='coco',min_area=0, min_visibility=0,label_fields=['labels'])\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TRAIN = 'frames_v2'\n",
    "\n",
    "class DrivingDataset(Dataset):\n",
    "    def __init__(self,image_ids,dataframe,transforms=None):\n",
    "        self.image_ids = image_ids\n",
    "        self.df = dataframe\n",
    "        self.transforms = transforms\n",
    "        self.label_map = {'car': 1,\n",
    "                       'pedestrian': 2,\n",
    "                       'truck': 3,\n",
    "                       'bus': 4,\n",
    "                       'bicycle': 5,\n",
    "                       'rider': 6,\n",
    "                       'other vehicle': 7,\n",
    "                       'motorcycle': 8,\n",
    "                       'other person': 9,\n",
    "                       'trailer': 10,\n",
    "                       'train': 11}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        image_id = self.image_ids[index]\n",
    "        records = self.df[self.df['name'] == image_id]\n",
    "\n",
    "        image = cv2.imread(f'{DIR_TRAIN}/{image_id}', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        # DETR takes in data in coco format\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values\n",
    "\n",
    "        #Area of bb\n",
    "        area = boxes[:,2]*boxes[:,3]\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "\n",
    "        # AS pointed out by PRVI It works better if the main class is labelled as zero\n",
    "        labels = records['category'].values\n",
    "        labels =  np.array([self.label_map[label] for label in labels], dtype=np.int32)\n",
    "\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': boxes,\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            boxes = sample['bboxes']\n",
    "            labels = sample['labels']\n",
    "\n",
    "\n",
    "        #Normalizing BBOXES\n",
    "\n",
    "        _,h,w = image.shape\n",
    "        boxes = A.core.bbox_utils.normalize_bboxes(sample['bboxes'],rows=h,cols=w)\n",
    "        target = {}\n",
    "        target['boxes'] = torch.as_tensor(boxes,dtype=torch.float32)\n",
    "        target['labels'] = torch.as_tensor(labels,dtype=torch.long)\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "        target['area'] = area\n",
    "\n",
    "        return image, target, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# train_dataset = DrivingDataset(image_ids=train_df.name.values, \n",
    "#                                dataframe=train_df, \n",
    "#                                transforms=get_train_transforms())\n",
    "\n",
    "# train_data_loader = DataLoader(train_dataset, \n",
    "#                                batch_size=BATCH_SIZE, \n",
    "#                                shuffle=False, \n",
    "#                                #num_workers=4, \n",
    "#                                collate_fn= collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DETRModel(nn.Module):\n",
    "    def __init__(self,num_classes,num_queries):\n",
    "        super(DETRModel,self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_queries = num_queries\n",
    "\n",
    "        self.model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
    "        self.in_features = self.model.class_embed.in_features\n",
    "\n",
    "        self.model.class_embed = nn.Linear(in_features=self.in_features,out_features=self.num_classes)\n",
    "        self.model.num_queries = self.num_queries\n",
    "\n",
    "    def forward(self,images):\n",
    "        return self.model(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching and Bipartite Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "code taken from github repo detr , 'code present in engine.py'\n",
    "'''\n",
    "\n",
    "matcher = HungarianMatcher()\n",
    "\n",
    "weight_dict = weight_dict = {'loss_ce': 1, 'loss_bbox': 1 , 'loss_giou': 1}\n",
    "\n",
    "losses = ['labels', 'boxes', 'cardinality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def train_fn(data_loader,model,criterion,optimizer,device,scheduler,epoch):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "\n",
    "    summary_loss = AverageMeter()\n",
    "\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "\n",
    "    for step, (images, targets, image_ids) in enumerate(tk0):\n",
    "\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "\n",
    "        output = model(images)\n",
    "\n",
    "#         print(output.shape)\n",
    "#         print(output)\n",
    "#         print(targets)\n",
    "        loss_dict = criterion(output, targets)\n",
    "        weight_dict = criterion.weight_dict\n",
    "\n",
    "        losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step < 10:\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        summary_loss.update(losses.item(),BATCH_SIZE)\n",
    "        tk0.set_postfix(loss=summary_loss.avg)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        del loss_dict, losses\n",
    "\n",
    "    return summary_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model,criterion, device):\n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    summary_loss = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for step, (images, targets, image_ids) in enumerate(tk0):\n",
    "\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            loss_dict = criterion(output, targets)\n",
    "            weight_dict = criterion.weight_dict\n",
    "\n",
    "            losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "            summary_loss.update(losses.item(),BATCH_SIZE)\n",
    "            tk0.set_postfix(loss=summary_loss.avg)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            del loss_dict, losses\n",
    "            \n",
    "    return summary_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing / exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = DrivingDataset(image_ids=train_df.name.values, \n",
    "#                                dataframe=train_df, \n",
    "#                                transforms=get_train_transforms())\n",
    "\n",
    "# train_data_loader = DataLoader(train_dataset, \n",
    "#                                batch_size=BATCH_SIZE, \n",
    "#                                    shuffle=True, #False, \n",
    "#                                    #num_workers=4, \n",
    "#                                    collate_fn= collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_batch(data_loader):\n",
    "#     images, targets, image_ids = next(iter(data_loader))\n",
    "#     fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "#     print(image_ids)\n",
    "#     for i in range(4):\n",
    "#         img = images[i].numpy().transpose(1, 2, 0)\n",
    "#         print(img.shape)\n",
    "#         ax[i].imshow(img)\n",
    "#         ax[i].axis('off')\n",
    "#     plt.show()\n",
    "    \n",
    "# visualize_batch(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('frames_v2/018bf09d-cd788942-0000085.jpg')\n",
    "# print(img.shape)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_rs = cv2.resize(img, (128, 72))\n",
    "# plt.imshow(img_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "\n",
    "#     df_train = df_folds[df_folds['fold'] != fold]\n",
    "#     df_valid = df_folds[df_folds['fold'] == fold]\n",
    "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "\n",
    "    train_dataset = DrivingDataset(image_ids=train_df.name.values, \n",
    "                                   dataframe=train_df, \n",
    "                                   transforms=get_train_transforms())\n",
    "\n",
    "    train_data_loader = DataLoader(train_dataset, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   shuffle=True, #False, \n",
    "                                   #num_workers=4, \n",
    "                                   collate_fn= collate_fn)\n",
    "    \n",
    "    print('train data loader made')\n",
    "    \n",
    "    test_dataset = DrivingDataset(image_ids=test_df.name.values, \n",
    "                                  dataframe=test_df,\n",
    "                                  transforms=get_valid_transforms())\n",
    "\n",
    "    test_data_loader = DataLoader(test_dataset, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   shuffle=True, #False, \n",
    "                                   #num_workers=4, \n",
    "                                   collate_fn= collate_fn)\n",
    "    \n",
    "    print('test data loader made')\n",
    "\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    model = DETRModel(num_classes=num_classes,num_queries=num_queries)\n",
    "    model = model.to(device)\n",
    "    criterion = SetCriterion(num_classes-1, matcher, weight_dict, eos_coef = null_class_coef, losses=losses) #changed from num_classes-1 to num_classes\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "    best_loss = 10**5\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        #train_loss = train_fn(train_data_loader, model,criterion, optimizer,device,scheduler=None,epoch=epoch)\n",
    "        valid_loss = eval_fn(test_data_loader, model,criterion, device)\n",
    "\n",
    "        print('|EPOCH {}| TRAIN_LOSS {}| VALID_LOSS {}|'.format(epoch+1,train_loss.avg,valid_loss.avg))\n",
    "        \n",
    "        train_losses.append(train_loss.avg)\n",
    "        test_losses.append(valid_loss.avg)\n",
    "        \n",
    "#         if valid_loss.avg < best_loss:\n",
    "#             best_loss = valid_loss.avg\n",
    "#             print('Best model found for Fold {} in Epoch {}........Saving Model'.format(fold,epoch+1))\n",
    "#             torch.save(model.state_dict(), f'detr_best_{fold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data loader made\n",
      "test data loader made\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/facebookresearch_detr_master\n",
      "  0%|          | 4/60712 [00:06<31:28:46,  1.87s/it, loss=2.8] "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8d7152b44077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-52682acb40df>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-da2aabc87d83>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, criterion, optimizer, device, scheduler, epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         print(targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mweight_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/detr/models/detr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# Retrieve the matching between the outputs of the last layer and the targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_without_aux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Compute the average number of target boxes accross all nodes, for normalization purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/detr/models/matcher.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# but approximate it in 1 - proba[target class].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# The 1 is a constant that doesn't change the matching, it can be ommitted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mcost_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mout_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Compute the L1 cost between boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "run(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # Wrap the model with nn.DataParallel\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPUs detected: \", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Total Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cuDNN Version:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated(), torch.cuda.max_memory_allocated(), torch.cuda.memory_reserved(), torch.cuda.max_memory_reserved() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
